<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>ANVA — TUG (Pose Only, Privacy Safe)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <!-- TFJS core -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@4.9.0/dist/tf-core.min.js"></script>

  <!-- Backends: WebGL + WASM (WASM is the iPhone lifesaver) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.9.0/dist/tf-backend-webgl.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm@4.9.0/dist/tf-backend-wasm.min.js"></script>

  <!-- Pose detection (MoveNet) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@0.0.8/dist/pose-detection.min.js"></script>

  <style>
    body{font-family:Arial,sans-serif;background:#f6f7f9;text-align:center;padding:16px;}
    h1{color:#0b5ed7;}
    .card{max-width:460px;margin:auto;background:#fff;padding:16px;border-radius:12px;box-shadow:0 6px 18px rgba(0,0,0,0.08);}
    button{padding:10px 14px;margin:6px;border-radius:8px;border:none;font-weight:700;cursor:pointer;}
    #startBtn{background:#0b5ed7;color:#fff;}
    #recordBtn{background:#198754;color:#fff;}
    #stopBtn{background:#dc3545;color:#fff;}
    button:disabled{opacity:0.4;cursor:not-allowed;}
    #status{margin-top:10px;font-weight:700;}

    /* iOS Safari: video must be "alive" but not visible */
    #video{
      position:fixed; top:0; left:0;
      width:2px; height:2px;
      opacity:0.01;          /* NOT 0 */
      pointer-events:none;
      z-index:-1;
    }
    canvas{width:100%;margin-top:10px;background:#000;border-radius:10px;}
    .small{font-size:12px;color:#444;margin-top:8px;line-height:1.3;}
  </style>
</head>

<body>
<h1>ANVA — TUG (Pose Only)</h1>

<div class="card">
  <p><b>Privacy mode:</b> Camera is used only to extract pose.<br><b>No video/images are ever saved.</b></p>

  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>

  <div>
    <button id="startBtn">Start Camera</button>
    <button id="recordBtn" disabled>Start TUG</button>
    <button id="stopBtn" disabled>Stop</button>
  </div>

  <div id="status">Idle</div>
  <div class="small" id="dbg"></div>
</div>

<script>
  const video = document.getElementById("video");
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");
  const startBtn = document.getElementById("startBtn");
  const recordBtn = document.getElementById("recordBtn");
  const stopBtn = document.getElementById("stopBtn");
  const statusEl = document.getElementById("status");
  const dbgEl = document.getElementById("dbg");

  let detector = null;
  let recording = false;
  let frameIndex = 0;
  let poseFrames = [];

  function setStatus(t){ statusEl.textContent = t; }
  function setDbg(t){ dbgEl.textContent = t; }

  function waitForVideo(timeoutMs=5000){
    return new Promise((resolve, reject) => {
      const t0 = Date.now();
      (function tick(){
        if (video.videoWidth > 0 && video.videoHeight > 0) return resolve();
        if (Date.now() - t0 > timeoutMs) return reject(new Error("Video never produced dimensions"));
        requestAnimationFrame(tick);
      })();
    });
  }

  function withTimeout(promise, ms, label){
    return new Promise((resolve, reject) => {
      const t = setTimeout(() => reject(new Error(label + " (timeout)")), ms);
      promise.then(v => { clearTimeout(t); resolve(v); })
             .catch(e => { clearTimeout(t); reject(e); });
    });
  }

  async function initBackend(){
    // WASM path required for tfjs-backend-wasm
    // (this tells TFJS where the .wasm binaries live)
    tf.wasm.setWasmPaths("https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm@4.9.0/dist/");

    // Try WebGL quickly; if it hangs, fall back to WASM.
    setStatus("Initializing TF backend (WebGL) …");
    try {
      await withTimeout(tf.setBackend("webgl"), 2000, "tf.setBackend(webgl)");
      await withTimeout(tf.ready(), 2000, "tf.ready(webgl)");
      setDbg("Backend: webgl");
      return "webgl";
    } catch (e) {
      console.warn("WebGL backend failed/hung, switching to WASM:", e);
      setStatus("WebGL stuck → switching to WASM …");
      await tf.setBackend("wasm");
      await tf.ready();
      setDbg("Backend: wasm");
      return "wasm";
    }
  }

  async function loadMoveNet(){
    // Pose detector creation can hang on iOS if backend is unhappy; guard it.
    setStatus("Loading pose model…");
    detector = await withTimeout(
      poseDetection.createDetector(
        poseDetection.SupportedModels.MoveNet,
        { modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING }
      ),
      8000,
      "createDetector(MoveNet)"
    );
    setStatus("Pose model ready.");
  }

  async function loop(){
    if (!detector) return requestAnimationFrame(loop);

    ctx.clearRect(0,0,canvas.width,canvas.height);

    try {
      const poses = await detector.estimatePoses(video, { maxPoses: 1 });
      if (poses && poses.length){
        const kps = poses[0].keypoints;

        // Draw points (preview only)
        ctx.fillStyle = "white";
        for (const k of kps){
          if (k.score > 0.4){
            ctx.beginPath();
            ctx.arc(k.x, k.y, 4, 0, Math.PI*2);
            ctx.fill();
          }
        }

        // Save points ONLY when recording
        if (recording){
          poseFrames.push({
            frame: frameIndex++,
            time_ms: performance.now(),
            keypoints: kps.map(k => ({
              name: k.name,
              x: k.x,
              y: k.y,
              score: k.score
            }))
          });
        }
      }
    } catch (e) {
      // If estimatePoses fails, show it once and keep looping
      setDbg("Pose error: " + (e?.message || e));
    }

    requestAnimationFrame(loop);
  }

  startBtn.onclick = async () => {
    try {
      setStatus("Requesting camera…");
      setDbg("");

      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "user" },
        audio: false
      });

      video.srcObject = stream;
      await video.play();

      setStatus("Starting video…");
      await waitForVideo(6000);

      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      // Backend first (with WASM fallback), then model
      const backend = await initBackend();
      setDbg("Backend: " + backend + " | Video: " + video.videoWidth + "x" + video.videoHeight);

      await loadMoveNet();

      recordBtn.disabled = false;
      setStatus("Ready. Press Start TUG.");
      requestAnimationFrame(loop);

    } catch (e) {
      console.error(e);
      setStatus("Failed to start. Refresh and try again.");
      setDbg(e?.message || String(e));
    }
  };

  recordBtn.onclick = () => {
    poseFrames = [];
    frameIndex = 0;
    recording = true;
    recordBtn.disabled = true;
    stopBtn.disabled = false;
    setStatus("Recording pose points…");
  };

  stopBtn.onclick = () => {
    recording = false;
    stopBtn.disabled = true;
    recordBtn.disabled = false;

    const blob = new Blob(
      [JSON.stringify({ fps: 30, frames: poseFrames }, null, 2)],
      { type: "application/json" }
    );

    const a = document.createElement("a");
    a.href = URL.createObjectURL(blob);
    a.download = "TUG_pose_only.json";
    a.click();

    setStatus("Saved: TUG_pose_only.json (privacy-safe)");
  };
</script>
</body>
</html>
