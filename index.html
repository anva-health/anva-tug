<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover" />
  <title>ANVA — TUG (Pose Only)</title>

  <style>
    :root{
      --brand:#0b5ed7;
      --ok:#198754;
      --warn:#b3261e;
      --muted:#6b7280;
      --bg:#f6f7f9;
      --card:#ffffff;
    }
    body{
      margin:0;
      font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif;
      background:var(--bg);
      color:#111827;
      text-align:center;
      padding:16px 14px 28px;
    }
    h1{
      margin:10px 0 4px;
      color:var(--brand);
      font-size:30px;
      letter-spacing:0.2px;
    }
    .sub{
      margin:0 0 14px;
      color:var(--muted);
      font-weight:700;
    }
    .card{
      max-width:520px;
      margin:0 auto;
      background:var(--card);
      border-radius:18px;
      padding:14px;
      box-shadow: 0 10px 28px rgba(0,0,0,0.08);
    }
    .hint{
      text-align:left;
      background:#f3f4f6;
      border-radius:14px;
      padding:12px 12px;
      margin:10px 0 12px;
      line-height:1.25;
      font-size:14px;
    }
    .hint b{ font-weight:900; }
    .stage{
      position:relative;
      width:100%;
      max-width:480px;
      margin:10px auto 12px;
      border-radius:16px;
      overflow:hidden;
      background:#000;
      touch-action: manipulation;
    }
    video, canvas{
      width:100%;
      height:auto;
      display:block;
      background:#000;
    }
    #video{
      position:absolute;
      inset:0;
      opacity:0;
      pointer-events:none;
    }
    #pill{
      position:absolute;
      left:10px;
      top:10px;
      z-index:5;
      padding:7px 12px;
      border-radius:999px;
      font-weight:900;
      font-size:12px;
      color:#fff;
      background:#111827cc;
      backdrop-filter: blur(4px);
    }
    #toast{
      position:absolute;
      left:50%;
      bottom:10px;
      transform:translateX(-50%);
      z-index:6;
      padding:9px 12px;
      border-radius:999px;
      font-weight:800;
      font-size:12px;
      color:#fff;
      background:#111827cc;
      opacity:0;
      transition:opacity 0.2s ease;
      pointer-events:none;
      max-width:92%;
      white-space:nowrap;
      overflow:hidden;
      text-overflow:ellipsis;
    }
    .row{
      display:flex;
      justify-content:center;
      gap:10px;
      flex-wrap:wrap;
      margin-top:10px;
    }
    button{
      border:none;
      border-radius:14px;
      padding:12px 14px;
      font-size:15px;
      font-weight:900;
      cursor:pointer;
      min-width:150px;
    }
    button.primary{ background:var(--brand); color:#fff; }
    button.good{ background:var(--ok); color:#fff; }
    button.secondary{ background:#9ca3af; color:#fff; }
    button.danger{ background:var(--warn); color:#fff; }
    button:disabled{
      opacity:0.45;
      cursor:not-allowed;
    }
    .checks{
      text-align:left;
      max-width:480px;
      margin:6px auto 0;
      color:#111827;
      font-size:14px;
    }
    .checks label{ display:block; margin:8px 0; }
    .status{
      margin-top:12px;
      font-weight:900;
      color:#065f46;
    }
    .status.warn{ color:var(--warn); }
    .workflow{
      margin-top:10px;
      color:#111827;
      font-size:14px;
      line-height:1.25;
    }
    .mono{
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size:12px;
      color:#374151;
      text-align:left;
      background:#f3f4f6;
      border-radius:12px;
      padding:10px;
      overflow:auto;
      max-height:160px;
      margin-top:10px;
    }
  </style>

  <!-- TFJS + MoveNet -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@2.1.3/dist/pose-detection.min.js"></script>
</head>

<body>
  <h1>ANVA — TUG (Pose Only)</h1>
  <p class="sub">Privacy mode: camera used only to extract pose. No video/images are saved.</p>

  <div class="card">
    <div class="hint">
      <b>Setup:</b> Frontal view. Full body <b>below neck</b> + feet visible. Blue tape visible on floor. <br/>
      <b>Tape step:</b> After camera starts, <b>tap directly on the blue tape</b> in the preview to lock tape level.
    </div>

    <div class="stage" id="stage">
      <div id="pill">READY</div>
      <div id="toast"></div>

      <!-- video is optional preview only -->
      <video id="video" playsinline muted></video>
      <!-- canvas shows stick figure (no camera pixels) -->
      <canvas id="canvas"></canvas>
    </div>

    <div class="checks">
      <label><input type="checkbox" id="showLive"> Show live video under stick figure (preview only)</label>
      <label><input type="checkbox" id="saveStick" checked> Record stick-figure-only video (no pixels) as WebM</label>
    </div>

    <div class="row">
      <button class="primary" id="btnStartCam">Start Camera</button>
      <button class="secondary" id="btnSwitch">Switch Camera</button>
    </div>

    <div class="row">
      <button class="good" id="btnSetTape" disabled>Set Tape (tap on tape)</button>
      <button class="danger" id="btnStart" disabled>Start TUG</button>
    </div>

    <div class="row">
      <button class="secondary" id="btnStop" disabled>Stop</button>
    </div>

    <div class="status" id="statusLine">Libraries loading…</div>

    <div class="workflow">
      <b>Workflow:</b> Start Camera → tap tape → Set Tape turns green → Start TUG → Stop → JSON downloads
    </div>

    <div class="mono" id="debug"></div>
  </div>

<script>
(() => {
  // ---------- DOM ----------
  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  const stage = document.getElementById('stage');
  const ctx = canvas.getContext('2d');

  const pill = document.getElementById('pill');
  const toast = document.getElementById('toast');
  const statusLine = document.getElementById('statusLine');
  const debugEl = document.getElementById('debug');

  const btnStartCam = document.getElementById('btnStartCam');
  const btnSwitch = document.getElementById('btnSwitch');
  const btnSetTape = document.getElementById('btnSetTape');
  const btnStart = document.getElementById('btnStart');
  const btnStop = document.getElementById('btnStop');

  const showLive = document.getElementById('showLive');
  const saveStick = document.getElementById('saveStick');

  // ---------- State ----------
  let detector = null;
  let stream = null;
  let facingMode = 'environment'; // default rear camera (often better for floor)
  let rafId = null;

  let lastGoodPoseTs = 0;
  let headDetected = false;

  // Tape calibration (normalized 0..1)
  let tape_y_norm = null;

  // Capture
  let capturing = false;
  let frames = [];
  let captureStartMs = 0;
  let mediaRecorder = null;
  let stickChunks = [];

  // ---------- Helpers ----------
  function log(msg){
    debugEl.textContent = (debugEl.textContent + msg + "\n").slice(-6000);
    debugEl.scrollTop = debugEl.scrollHeight;
  }

  function setPill(text, bg){
    pill.textContent = text;
    pill.style.background = bg || '#111827cc';
  }

  function showToast(msg){
    toast.textContent = msg;
    toast.style.opacity = '1';
    clearTimeout(showToast._t);
    showToast._t = setTimeout(() => toast.style.opacity = '0', 1600);
  }

  function nowMs(){ return performance.now(); }

  function downloadBlob(blob, filename){
    const a = document.createElement('a');
    a.href = URL.createObjectURL(blob);
    a.download = filename;
    document.body.appendChild(a);
    a.click();
    setTimeout(() => {
      URL.revokeObjectURL(a.href);
      a.remove();
    }, 0);
  }

  function clamp01(x){ return Math.max(0, Math.min(1, x)); }

  function canvasRect(){
    return canvas.getBoundingClientRect();
  }

  function getTapYNorm(evt){
    const r = canvasRect();
    const clientY = (evt.touches && evt.touches[0]) ? evt.touches[0].clientY : evt.clientY;
    const y = clientY - r.top;
    return clamp01(y / r.height);
  }

  // Privacy guard: if any of these are confidently detected, head is in frame.
  const HEAD_KPS = ['nose','left_eye','right_eye','left_ear','right_ear'];

  function poseToKeypoints(pose){
    // pose-detection returns keypoints with name, x, y, score
    const out = [];
    for (const kp of pose.keypoints || []){
      out.push({
        name: kp.name || kp.part || '',
        x: Number(kp.x ?? 0),
        y: Number(kp.y ?? 0),
        score: Number(kp.score ?? 0)
      });
    }
    return out;
  }

  function getKpByName(kps){
    const m = {};
    for (const k of kps) m[k.name] = k;
    return m;
  }

  function drawStick(kps){
    // Clear
    ctx.clearRect(0,0,canvas.width,canvas.height);

    // Background black already from canvas style
    // Draw joints + simple connections
    const K = getKpByName(kps);
    const minScore = 0.25;

    function dot(name){
      const p = K[name];
      if (!p || p.score < minScore) return;
      ctx.beginPath();
      ctx.arc(p.x, p.y, 5, 0, Math.PI*2);
      ctx.fillStyle = '#00ff99';
      ctx.fill();
    }
    function line(a,b){
      const p = K[a], q = K[b];
      if (!p || !q) return;
      if (p.score < minScore || q.score < minScore) return;
      ctx.beginPath();
      ctx.moveTo(p.x,p.y);
      ctx.lineTo(q.x,q.y);
      ctx.lineWidth = 4;
      ctx.strokeStyle = '#00ff99';
      ctx.stroke();
    }

    // Skeleton (MoveNet-ish)
    const links = [
      ['left_shoulder','right_shoulder'],
      ['left_shoulder','left_elbow'], ['left_elbow','left_wrist'],
      ['right_shoulder','right_elbow'], ['right_elbow','right_wrist'],
      ['left_shoulder','left_hip'], ['right_shoulder','right_hip'],
      ['left_hip','right_hip'],
      ['left_hip','left_knee'], ['left_knee','left_ankle'],
      ['right_hip','right_knee'], ['right_knee','right_ankle']
    ];
    for (const [a,b] of links) line(a,b);

    // Dots for main joints
    ['left_shoulder','right_shoulder','left_hip','right_hip','left_knee','right_knee','left_ankle','right_ankle',
     'left_elbow','right_elbow','left_wrist','right_wrist'].forEach(dot);

    // Optional: if live video is enabled, show beneath (preview only)
    // (We do that by setting video opacity; no pixels saved.)
  }

  async function initModel(){
    statusLine.textContent = 'Loading pose model…';
    const model = poseDetection.SupportedModels.MoveNet;
    detector = await poseDetection.createDetector(model, {
      modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING
    });
    statusLine.textContent = 'Libraries loaded. Tap Start Camera.';
    log('Model loaded.');
  }

  async function startCamera(){
    if (stream){
      stream.getTracks().forEach(t => t.stop());
      stream = null;
    }

    const constraints = {
      audio: false,
      video: {
        facingMode: { ideal: facingMode },
        width: { ideal: 720 },
        height: { ideal: 1280 }
      }
    };

    statusLine.textContent = 'Starting camera…';
    setPill('WAIT', '#b45309cc');

    stream = await navigator.mediaDevices.getUserMedia(constraints);
    video.srcObject = stream;
    await video.play();

    // Size canvas to match video
    const vw = video.videoWidth || 720;
    const vh = video.videoHeight || 1280;
    canvas.width = vw;
    canvas.height = vh;

    // Live preview toggle
    video.style.opacity = showLive.checked ? '0.35' : '0.0';

    tape_y_norm = null;
    btnSetTape.disabled = false;
    btnSetTape.classList.remove('good');
    btnSetTape.classList.add('good'); // stays green style but we’ll indicate by text
    btnSetTape.textContent = 'Set Tape (tap on tape)';

    btnStart.disabled = true;
    btnStop.disabled = true;

    headDetected = false;
    lastGoodPoseTs = 0;

    statusLine.textContent = 'Camera started. Tap the blue tape, then press Set Tape.';
    showToast('Camera started ✅ Now tap the blue tape.');
    log(`Camera started. facingMode=${facingMode} size=${vw}x${vh}`);

    // Start loop
    if (!rafId) loop();
  }

  function stopAll(){
    capturing = false;
    btnStop.disabled = true;
    btnStart.disabled = true;

    if (rafId){
      cancelAnimationFrame(rafId);
      rafId = null;
    }
    if (stream){
      stream.getTracks().forEach(t => t.stop());
      stream = null;
    }
    video.srcObject = null;

    setPill('READY', '#111827cc');
    statusLine.textContent = 'Stopped.';
  }

  function canStartTug(){
    // Must have tape set, must have recent good pose, and must NOT detect head
    const okPose = (nowMs() - lastGoodPoseTs) < 1200;
    return (!!tape_y_norm) && okPose && !headDetected;
  }

  async function loop(){
    rafId = requestAnimationFrame(loop);

    if (!detector || !stream) return;

    // Keep preview opacity in sync
    video.style.opacity = showLive.checked ? '0.35' : '0.0';

    // Estimate pose
    let poses = [];
    try{
      poses = await detector.estimatePoses(video, { maxPoses: 1, flipHorizontal: false });
    }catch(e){
      // Don’t spam
      return;
    }
    if (!poses || poses.length === 0) return;

    const pose = poses[0];
    const kps = poseToKeypoints(pose);
    drawStick(kps);

    // Determine if pose is "good enough"
    const K = getKpByName(kps);
    const lA = K['left_ankle'], rA = K['right_ankle'];
    const lH = K['left_hip'], rH = K['right_hip'];
    const poseGood =
      (lA && rA && lH && rH) &&
      (lA.score > 0.25 && rA.score > 0.25 && lH.score > 0.25 && rH.score > 0.25);

    if (poseGood){
      lastGoodPoseTs = nowMs();
    }

    // Privacy: head detected?
    headDetected = false;
    for (const n of HEAD_KPS){
      const p = K[n];
      if (p && p.score >= 0.35){
        headDetected = true;
        break;
      }
    }

    // UI status
    if (!poseGood){
      setPill('WAIT', '#b45309cc');
    } else if (headDetected){
      setPill('HEAD DETECTED', '#b3261ecc');
    } else if (!tape_y_norm){
      setPill('TAP TAPE', '#0f766ecc');
    } else {
      setPill('READY', '#065f46cc');
    }

    // Enable Start TUG appropriately
    btnStart.disabled = !canStartTug();

    // If capturing, store frame
    if (capturing){
      const t_ms = Math.round((nowMs() - captureStartMs)); // relative ms
      frames.push({
        t_ms,
        w: canvas.width,
        h: canvas.height,
        keypoints: kps
      });
    }
  }

  function startCapture(){
    if (!canStartTug()){
      showToast('Need: tape set + good pose + no head in frame.');
      return;
    }

    capturing = true;
    frames = [];
    captureStartMs = nowMs();

    btnStop.disabled = false;
    btnStart.disabled = true;
    btnSetTape.disabled = true;
    btnStartCam.disabled = true;
    btnSwitch.disabled = true;

    statusLine.textContent = 'Capturing… (keypoints only)';
    showToast('Capturing started ✅');

    // Optional: record stick-figure-only WebM from canvas stream
    if (saveStick.checked){
      try{
        stickChunks = [];
        const canvasStream = canvas.captureStream(30);
        mediaRecorder = new MediaRecorder(canvasStream, { mimeType: 'video/webm;codecs=vp8' });
        mediaRecorder.ondataavailable = (e) => { if (e.data && e.data.size) stickChunks.push(e.data); };
        mediaRecorder.start();
      }catch(e){
        log('Stick video recording not supported on this device/browser.');
        mediaRecorder = null;
      }
    }
  }

  function stopCapture(){
    if (!capturing) return;
    capturing = false;

    btnStop.disabled = true;
    btnSetTape.disabled = false;
    btnStartCam.disabled = false;
    btnSwitch.disabled = false;

    // Stop recorder if present
    if (mediaRecorder){
      try{ mediaRecorder.stop(); }catch(e){}
    }

    // Build JSON
    const ts = new Date();
    const pad = (n) => String(n).padStart(2,'0');
    const stamp = `${ts.getFullYear()}-${pad(ts.getMonth()+1)}-${pad(ts.getDate())}_${pad(ts.getHours())}${pad(ts.getMinutes())}`;

    const payload = {
      meta: {
        app: 'ANVA_TUG_POSE_ONLY',
        version: 'tap-tape-v1',
        created_local: ts.toString(),
        facingMode,
        tape_y_norm: tape_y_norm,     // <--- the important piece
        note: 'No camera pixels saved. Keypoints only.'
      },
      frames
    };

    const jsonBlob = new Blob([JSON.stringify(payload)], { type:'application/json' });
    downloadBlob(jsonBlob, `ANVA_TUG_KEYPOINTS_${stamp}.json`);
    statusLine.textContent = `Saved JSON: ${frames.length} frames.`;

    // Save stick video if available
    if (stickChunks && stickChunks.length){
      const webm = new Blob(stickChunks, { type:'video/webm' });
      downloadBlob(webm, `ANVA_TUG_STICK_${stamp}.webm`);
      stickChunks = [];
    }

    showToast('Saved ✅ JSON downloaded');
    log(`Saved capture. frames=${frames.length} tape_y_norm=${tape_y_norm}`);

    // Re-enable Start if still valid
    btnStart.disabled = !canStartTug();
  }

  // ---------- Tape tap logic ----------
  function armTapeTap(){
    // User taps directly on the tape in the preview area
    const y = getTapYNorm(event);
  }

  function setTapeFromTap(yNorm){
    tape_y_norm = clamp01(yNorm);

    btnSetTape.textContent = 'Tape Locked ✅';
    showToast(`Tape locked (y=${tape_y_norm.toFixed(3)})`);

    // Enable Start if pose is good and privacy OK
    btnStart.disabled = !canStartTug();
    statusLine.textContent = 'Tape set. Now you can Start TUG.';
    log(`Tape set: tape_y_norm=${tape_y_norm.toFixed(4)}`);
  }

  // We accept tap on the STAGE (canvas area). No overlay line is drawn.
  stage.addEventListener('click', (e) => {
    if (!stream) return;
    // If the user hasn't set tape yet, tap sets it immediately:
    const yNorm = getTapYNorm(e);
    setTapeFromTap(yNorm);
  });

  stage.addEventListener('touchstart', (e) => {
    if (!stream) return;
    const yNorm = getTapYNorm(e);
    setTapeFromTap(yNorm);
  }, { passive:true });

  // Button Set Tape just reminds user; tapping sets it.
  btnSetTape.addEventListener('click', () => {
    if (!stream){
      showToast('Start Camera first.');
      return;
    }
    showToast('Now tap directly on the blue tape in the preview.');
    statusLine.textContent = 'Tap the blue tape line in the preview area.';
  });

  // ---------- Events ----------
  btnStartCam.addEventListener('click', async () => {
    try{
      await startCamera();
    }catch(e){
      statusLine.textContent = 'Camera error. Check permissions.';
      showToast('Camera permission denied or unavailable.');
      log(String(e));
    }
  });

  btnSwitch.addEventListener('click', async () => {
    facingMode = (facingMode === 'environment') ? 'user' : 'environment';
    showToast(`Switching camera…`);
    if (stream){
      await startCamera();
    }
  });

  btnStart.addEventListener('click', startCapture);
  btnStop.addEventListener('click', stopCapture);

  showLive.addEventListener('change', () => {
    video.style.opacity = showLive.checked ? '0.35' : '0.0';
  });

  // ---------- Init ----------
  (async () => {
    try{
      await initModel();
      setPill('READY', '#111827cc');
    }catch(e){
      statusLine.textContent = 'Model load error (network blocked?)';
      log(String(e));
    }
  })();
})();
</script>
</body>
</html>

