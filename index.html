<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>ANVA — TUG (Pose Only, Privacy Safe)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <!-- TensorFlow + MoveNet -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@4.9.0/dist/tf-core.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.9.0/dist/tf-backend-webgl.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@0.0.8/dist/pose-detection.min.js"></script>

  <style>
    body {
      font-family: Arial, sans-serif;
      background: #f6f7f9;
      text-align: center;
      padding: 16px;
    }
    h1 { color: #0b5ed7; }

    .card {
      max-width: 460px;
      margin: auto;
      background: white;
      padding: 16px;
      border-radius: 12px;
      box-shadow: 0 6px 18px rgba(0,0,0,0.08);
    }

    button {
      padding: 10px 14px;
      margin: 6px;
      border-radius: 8px;
      border: none;
      font-weight: 700;
      cursor: pointer;
    }
    #startBtn { background:#0b5ed7; color:white; }
    #recordBtn { background:#198754; color:white; }
    #stopBtn { background:#dc3545; color:white; }
    button:disabled { opacity:0.4; cursor:not-allowed; }

    #status { margin-top:10px; font-weight:700; }

    /* IMPORTANT: video must exist but be invisible (NOT display:none) */
    video {
      position: absolute;
      top: -10000px;
      left: -10000px;
      width: 1px;
      height: 1px;
      opacity: 0;
    }

    canvas {
      width:100%;
      margin-top:10px;
      background:#000;
      border-radius:10px;
    }
  </style>
</head>

<body>
<h1>ANVA — TUG (Pose Only)</h1>

<div class="card">
  <p>
    <b>Privacy mode:</b><br>
    Camera is used only to extract pose.<br>
    <b>No video or images are ever saved.</b>
  </p>

  <!-- Raw camera feed (hidden but alive for Safari) -->
  <video id="video" autoplay playsinline muted></video>

  <!-- Skeleton preview (optional, points only) -->
  <canvas id="canvas"></canvas>

  <div>
    <button id="startBtn">Start Camera</button>
    <button id="recordBtn" disabled>Start TUG</button>
    <button id="stopBtn" disabled>Stop</button>
  </div>

  <div id="status">Idle</div>
</div>

<script>
let video = document.getElementById("video");
let canvas = document.getElementById("canvas");
let ctx = canvas.getContext("2d");

let startBtn = document.getElementById("startBtn");
let recordBtn = document.getElementById("recordBtn");
let stopBtn = document.getElementById("stopBtn");
let statusEl = document.getElementById("status");

let detector = null;
let stream = null;
let recording = false;
let frameIndex = 0;

/* THIS is the ONLY data that gets saved */
let poseFrames = [];

/* ---------- Load MoveNet AFTER video is live ---------- */
async function loadDetector() {
  await tf.ready();
  detector = await poseDetection.createDetector(
    poseDetection.SupportedModels.MoveNet,
    { modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING }
  );
}

/* ---------- Start Camera ---------- */
startBtn.onclick = async () => {
  statusEl.textContent = "Requesting camera…";

  stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: "user" },
    audio: false
  });

  video.srcObject = stream;

  /* IMPORTANT: wait for real video frames */
  await video.play();

  await new Promise(resolve => {
    const check = () => {
      if (video.videoWidth > 0 && video.videoHeight > 0) resolve();
      else requestAnimationFrame(check);
    };
    check();
  });

  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;

  statusEl.textContent = "Loading pose model…";
  await loadDetector();

  statusEl.textContent = "Camera ready. Press Start TUG.";
  recordBtn.disabled = false;

  requestAnimationFrame(loop);
};

/* ---------- Main Loop ---------- */
async function loop() {
  if (!video.videoWidth) return requestAnimationFrame(loop);

  ctx.clearRect(0,0,canvas.width,canvas.height);

  const poses = await detector.estimatePoses(video, { maxPoses:1 });
  if (poses.length > 0) {
    drawSkeleton(poses[0].keypoints);

    if (recording) {
      poseFrames.push({
        frame: frameIndex++,
        time_ms: performance.now(),
        keypoints: poses[0].keypoints.map(k => ({
          name: k.name,
          x: k.x,
          y: k.y,
          score: k.score
        }))
      });
    }
  }
  requestAnimationFrame(loop);
}

/* ---------- Skeleton Preview ---------- */
function drawSkeleton(kps) {
  ctx.fillStyle = "white";
  for (let k of kps) {
    if (k.score > 0.4) {
      ctx.beginPath();
      ctx.arc(k.x, k.y, 4, 0, Math.PI * 2);
      ctx.fill();
    }
  }
}

/* ---------- Controls ---------- */
recordBtn.onclick = () => {
  poseFrames = [];
  frameIndex = 0;
  recording = true;
  recordBtn.disabled = true;
  stopBtn.disabled = false;
  statusEl.textContent = "Recording pose points…";
};

stopBtn.onclick = () => {
  recording = false;
  stopBtn.disabled = true;
  recordBtn.disabled = false;
  statusEl.textContent = "Saving pose data…";

  const blob = new Blob(
    [JSON.stringify({ fps:30, frames: poseFrames }, null, 2)],
    { type:"application/json" }
  );

  const url = URL.createObjectURL(blob);
  const a = document.createElement("a");
  a.href = url;
  a.download = "TUG_pose_only.json";
  a.click();
  URL.revokeObjectURL(url);

  statusEl.textContent = "Saved: TUG_pose_only.json (privacy-safe)";
};
</script>
</body>
</html>
