<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>ANVA – TUG (Skeleton + JSON)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover" />

  <style>
    body { font-family: Arial, sans-serif; background:#f6f7f9; text-align:center; padding:16px; margin:0; }
    h1 { color:#0b5ed7; margin: 8px 0 14px; font-size:44px; font-weight:800; }
    #wrap { width:100%; max-width:420px; margin:0 auto; }

    #btnRow { display:flex; justify-content:center; gap:14px; margin: 6px 0 12px; flex-wrap:wrap; }
    button{
      font-size:18px; padding:12px 16px; border-radius:12px; border:none;
      cursor:pointer; touch-action: manipulation; min-width:118px;
      box-shadow: 0 2px 0 rgba(0,0,0,0.08);
    }
    #startBtn{ background:#0b5ed7; color:#fff; }
    #recordBtn{ background:#198754; color:#fff; }
    #stopBtn{ background:#adb5bd; color:#fff; }
    button:disabled{ opacity:0.55; cursor:not-allowed; box-shadow:none; }

    /* ONE viewport: video + canvas overlap here */
    #stage{
      position:relative;
      width:100%;
      aspect-ratio: 9 / 16;
      border-radius:12px;
      overflow:hidden;
      background:#000;         /* black privacy background */
      touch-action:none;       /* prevent scroll from stealing taps */
    }

    /* Video is the sensor ONLY (never visible) */
    video{
      position:absolute;
      inset:0;
      width:100%;
      height:100%;
      object-fit: cover;
      opacity:0;               /* privacy: never show pixels */
      z-index:1;
    }

    /* Canvas is the only thing user sees */
    canvas{
      position:absolute;
      inset:0;
      width:100%;
      height:100%;
      z-index:2;
      pointer-events:none;
    }

    /* Blue tape overlay (tap this to toggle skeleton mode) */
    #tape{
      position:absolute;
      left:0;
      width:100%;
      height:12px;
      background:#1677ff;
      opacity:0.9;
      top:72%;
      z-index:5;
      border-radius:10px;
      touch-action: manipulation;
    }
    #tapeText{
      position:absolute;
      left:0;
      width:100%;
      top:calc(72% - 18px);
      z-index:6;
      color:#eaf2ff;
      font-weight:800;
      font-size:14px;
      text-shadow:0 1px 2px rgba(0,0,0,0.8);
      pointer-events:none;
    }

    #banner{
      margin:12px auto 10px;
      width:100%;
      max-width:420px;
      background:#0f7a3a;
      color:#fff;
      border-radius:12px;
      padding:10px 12px;
      box-sizing:border-box;
      font-size:18px;
      display:flex;
      align-items:center;
      justify-content:center;
      gap:10px;
    }
    #dot{ width:16px; height:16px; border-radius:50%; background:#2dff6a; box-shadow:0 0 10px rgba(45,255,106,0.7); }

    #statusBar{
      margin:10px auto 0;
      width: 100%;
      max-width:420px;
      background:#e9ecef;
      border-radius:12px;
      padding:10px 12px;
      box-sizing:border-box;
      display:flex;
      gap:10px;
      justify-content:space-between;
      flex-wrap:wrap;
      font-size:14px;
      color:#222;
    }
    .pill{
      background:#fff;
      padding:6px 10px;
      border-radius:999px;
      border:1px solid #d6d8db;
    }
  </style>

  <!-- TensorFlow.js + Pose Detection (MoveNet) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@4.20.0/dist/tf-core.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@4.20.0/dist/tf-converter.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.20.0/dist/tf-backend-webgl.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@2.1.3/dist/pose-detection.min.js"></script>
</head>

<body>
  <div id="wrap">
    <h1>ANVA TUG</h1>

    <div id="btnRow">
      <button id="startBtn" type="button">Start Camera</button>
      <button id="recordBtn" type="button" disabled>Record (JSON)</button>
      <button id="stopBtn" type="button" disabled>Stop</button>
    </div>

    <div id="stage">
      <video id="video" playsinline muted></video>
      <canvas id="canvas"></canvas>

      <div id="tape"></div>
      <div id="tapeText">TAP BLUE TAPE</div>
    </div>

    <div id="banner"><div id="dot"></div><div id="bannerText">Camera armed — tap tape for Skeleton</div></div>

    <div id="statusBar">
      <div class="pill" id="modePill">Mode: Camera</div>
      <div class="pill" id="recPill">REC: OFF</div>
      <div class="pill" id="framesPill">Frames: 0</div>
      <div class="pill" id="fpsPill">FPS: —</div>
      <div class="pill" id="tapePill">Tape y_norm: —</div>
    </div>
  </div>

<script>
(() => {
  // ---------- Elements ----------
  const video    = document.getElementById('video');
  const canvas   = document.getElementById('canvas');
  const ctx      = canvas.getContext('2d');

  const stage    = document.getElementById('stage');
  const tapeEl   = document.getElementById('tape');

  const startBtn = document.getElementById('startBtn');
  const recordBtn= document.getElementById('recordBtn');
  const stopBtn  = document.getElementById('stopBtn');

  const bannerText = document.getElementById('bannerText');
  const modePill = document.getElementById('modePill');
  const recPill  = document.getElementById('recPill');
  const framesPill = document.getElementById('framesPill');
  const fpsPill  = document.getElementById('fpsPill');
  const tapePill = document.getElementById('tapePill');

  // ---------- State ----------
  let stream = null;
  let detector = null;
  let rafId = null;

  let skeletonMode = false;     // tap tape toggles this
  let isRecording = false;
  let frames = [];
  let t0 = 0;

  let lastFrameTs = performance.now();
  let fps = 0;

  // Tape position measured from DOM every frame (no hardcoded tape_y_norm)
  let tapeYNorm = null; // 0..1 in stage space

  // ---------- Helpers ----------
  function setUIMode(){
    modePill.textContent = `Mode: ${skeletonMode ? 'Skeleton' : 'Camera'}`;
    bannerText.textContent = skeletonMode
      ? 'Skeleton Mode — press Record (JSON)'
      : 'Camera armed — tap tape for Skeleton';
  }

  function setUIRecording(on){
    isRecording = on;
    recPill.textContent = on ? "REC: ON" : "REC: OFF";
    recordBtn.disabled = on;
    stopBtn.disabled = !on;
    stopBtn.style.background = on ? "#dc3545" : "#adb5bd";
  }

  function resizeCanvasToVideo(){
    const w = video.videoWidth || 0;
    const h = video.videoHeight || 0;
    if (!w || !h) return;
    if (canvas.width !== w)  canvas.width = w;
    if (canvas.height !== h) canvas.height = h;
  }

  function updateTapeYNormFromDOM(){
    const stageRect = stage.getBoundingClientRect();
    const tapeRect  = tapeEl.getBoundingClientRect();
    const tapeCenterY = (tapeRect.top + tapeRect.bottom) / 2;
    const y = (tapeCenterY - stageRect.top) / stageRect.height;
    tapeYNorm = Math.max(0, Math.min(1, y));
    tapePill.textContent = `Tape y_norm: ${tapeYNorm.toFixed(2)}`;
  }

  function makeOldStyleFilename(){
    const now = new Date();
    const stamp =
      now.getFullYear() + "-" +
      String(now.getMonth()+1).padStart(2,'0') + "-" +
      String(now.getDate()).padStart(2,'0') + "-" +
      String(now.getHours()).padStart(2,'0') + "-" +
      String(now.getMinutes()).padStart(2,'0') + "-" +
      String(now.getSeconds()).padStart(2,'0');
    return `ANVA_TUG_KEYPOINTS_${stamp}.json`;
  }

  function downloadJSON(payloadObj){
    const blob = new Blob([JSON.stringify(payloadObj)], { type: "application/json" });
    const url  = URL.createObjectURL(blob);

    const a = document.createElement('a');
    a.href = url;
    a.download = makeOldStyleFilename();  // <<< your old naming convention
    document.body.appendChild(a);
    a.click();
    a.remove();

    setTimeout(() => URL.revokeObjectURL(url), 1500);
  }

  // ---------- Skeleton drawing ----------
  // MoveNet 17 keypoints edges
  const EDGES = [
    [5,7],[7,9],     // left arm
    [6,8],[8,10],    // right arm
    [5,6],           // shoulders
    [5,11],[6,12],   // torso
    [11,12],         // hips
    [11,13],[13,15], // left leg
    [12,14],[14,16], // right leg
  ];

  function drawTapeGuideLine(){
    if (tapeYNorm == null) return;
    const y = tapeYNorm * canvas.height;
    ctx.beginPath();
    ctx.moveTo(0, y);
    ctx.lineTo(canvas.width, y);
    ctx.lineWidth = 4;
    ctx.strokeStyle = "#1677ff";
    ctx.stroke();
  }

  function drawSkeleton(keypoints){
    // Black background (privacy)
    ctx.clearRect(0,0,canvas.width, canvas.height);

    // (Optional) draw tape line inside canvas for trust/debug
    drawTapeGuideLine();

    // points
    for (const kp of keypoints){
      if (!kp || kp.score < 0.25) continue;
      ctx.beginPath();
      ctx.arc(kp.x, kp.y, 4, 0, Math.PI*2);
      ctx.fillStyle = "#00ff7a";
      ctx.fill();
    }

    // edges
    ctx.lineWidth = 3;
    ctx.strokeStyle = "#00ff7a";
    for (const [a,b] of EDGES){
      const ka = keypoints[a], kb = keypoints[b];
      if (!ka || !kb) continue;
      if (ka.score < 0.25 || kb.score < 0.25) continue;
      ctx.beginPath();
      ctx.moveTo(ka.x, ka.y);
      ctx.lineTo(kb.x, kb.y);
      ctx.stroke();
    }
  }

  // ---------- Recording ----------
  function pushFrame(pose){
    const kps = pose.keypoints.map(k => ({
      x: +(k.x / canvas.width).toFixed(5),
      y: +(k.y / canvas.height).toFixed(5),
      s: +(+k.score).toFixed(5)
    }));

    frames.push({
      t_ms: Math.round(performance.now() - t0),
      tape_y_norm: tapeYNorm == null ? null : +tapeYNorm.toFixed(5),
      kps
    });

    framesPill.textContent = `Frames: ${frames.length}`;
  }

  // ---------- TFJS + MoveNet ----------
  async function initDetector(){
    await tf.setBackend('webgl');
    await tf.ready();

    const model = poseDetection.SupportedModels.MoveNet;
    detector = await poseDetection.createDetector(model, {
      modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING
    });
  }

  // ---------- Camera: FORCE back camera by deviceId (iOS reliable) ----------
  async function getBackCameraStream(){
    // 1) Ask once for permission so device labels populate
    const tempStream = await navigator.mediaDevices.getUserMedia({ video:true, audio:false });
    tempStream.getTracks().forEach(t => t.stop());

    // 2) Enumerate
    const devices = await navigator.mediaDevices.enumerateDevices();
    const cams = devices.filter(d => d.kind === "videoinput");
    if (!cams.length) throw new Error("No camera devices found");

    // 3) Choose back camera
    const backCam =
      cams.find(d => /back|rear|environment/i.test(d.label)) ||
      cams[cams.length - 1] ||
      cams[0];

    // 4) Request exact deviceId
    return navigator.mediaDevices.getUserMedia({
      audio:false,
      video:{
        deviceId: { exact: backCam.deviceId },
        width: { ideal: 720 },
        height: { ideal: 1280 }
      }
    });
  }

  async function startCamera(){
    if (stream) return;

    stream = await getBackCameraStream();
    video.srcObject = stream;
    await video.play();

    await initDetector();

    recordBtn.disabled = false;

    cancelAnimationFrame(rafId);
    rafId = requestAnimationFrame(loop);
  }

  // ---------- Main loop ----------
  async function loop(){
    try{
      updateTapeYNormFromDOM();

      // FPS
      const now = performance.now();
      const dt = now - lastFrameTs;
      lastFrameTs = now;
      if (dt > 0) fps = 1000 / dt;
      fpsPill.textContent = `FPS: ${fps.toFixed(0)}`;

      resizeCanvasToVideo();

      if (!detector || video.readyState < 2 || !canvas.width || !canvas.height){
        rafId = requestAnimationFrame(loop);
        return;
      }

      const poses = await detector.estimatePoses(video, { flipHorizontal: true });
      const pose = poses && poses[0] ? poses[0] : null;

      if (pose && pose.keypoints && pose.keypoints.length){
        // privacy-correct: user only sees skeleton on black
        if (skeletonMode){
          drawSkeleton(pose.keypoints);
        } else {
          // Camera mode still shows black (no pixels), but no skeleton.
          ctx.clearRect(0,0,canvas.width, canvas.height);
        }

        if (isRecording){
          pushFrame(pose);
        }
      } else {
        ctx.clearRect(0,0,canvas.width, canvas.height);
      }

      rafId = requestAnimationFrame(loop);
    } catch (err){
      console.error(err);
      rafId = requestAnimationFrame(loop);
    }
  }

  // ---------- Events (pointerup is iOS-friendly) ----------
  startBtn.addEventListener('pointerup', async (e) => {
    e.preventDefault(); e.stopPropagation();
    try{
      startBtn.disabled = true;
      await startCamera();
      setUIMode();
    } catch(err){
      console.error(err);
      alert("Camera start failed. Check permissions and reload.");
      startBtn.disabled = false;
    }
  });

  // Tap tape toggles skeleton mode (your UX)
  tapeEl.addEventListener('pointerup', (e) => {
    e.preventDefault(); e.stopPropagation();
    skeletonMode = !skeletonMode;
    setUIMode();
  });

  recordBtn.addEventListener('pointerup', (e) => {
    e.preventDefault(); e.stopPropagation();
    if (!detector) return;

    frames = [];
    t0 = performance.now();
    framesPill.textContent = "Frames: 0";
    setUIRecording(true);
  });

  stopBtn.addEventListener('pointerup', (e) => {
    e.preventDefault(); e.stopPropagation();
    if (!isRecording) return;

    setUIRecording(false);

    // Download MUST happen inside this user gesture on iOS
    const payload = {
      version: "ANVA_TUG_KEYPOINTS_v1",
      created_iso: new Date().toISOString(),
      frames
    };

    downloadJSON(payload);
  });

  // Initial UI
  setUIMode();
  setUIRecording(false);

})();
</script>
</body>
</html>
